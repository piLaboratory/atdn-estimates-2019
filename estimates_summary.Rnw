\documentclass[12pt, A4]{article}
%\usepackage[brazil]{babel}
\usepackage{graphicx}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{url}
\usepackage{natbib}
\usepackage{amsmath}
\bibliographystyle{rusnat}
\usepackage{framed, color}
\usepackage{xspace}
\definecolor{shadecolor}{rgb}{0.9, 0.9, 0.9}
\newcommand{\R}{\textnormal{\sffamily\bfseries R}\xspace}
\newcommand{\code}[1]{\texttt{#1}}


\title{Estimates of total tree richness in Amazon - Summary}
\author{Han Ter Steege, Paulo In√°cio Prado, Renato Lima, ATDN}

\begin{document}

\maketitle


<<setup, echo=FALSE, include=FALSE>>=
library(VGAM)
library(untb)
#library(fitdistrplus)
library(sads)
library(knitr)
#library(SPECIES)
library(xtable)
library(abc)
source("functions.R")
opts_chunk$set(fig.align = 'center', fig.show = 'hold',
               fig.height = 6.5, warning = FALSE, message = FALSE,
               error = FALSE, echo=TRUE)
options(formatR.arrow = TRUE, width = 90, cache=TRUE, scipen = 1, digits = 2)
@ %def 

\section{Data preparation}

<<Data prep>>=
Dec2018 <- read.csv2("Populations_2018_V2b.csv", as.is=TRUE)
N.ind <- Dec2018$N.ind
Sobs <- length(N.ind)
## Total number of trees (average density x area)
Tot.t <- 567*5.5e8
## Proportion of total trees in the sample
p1 <- sum(Dec2018$N.ind)/Tot.t
## Total number of plots
N.plots <- 1945
## Total area hectares
Tot.A <- 5.79e8
## Sampled area ha
Samp.A <- 2.048e3
@ 

\section{Estimates from the plots sample}

\subsection*{Poisson lognormal}

Seems to overestimate the abundance of the most abundant species (see qq-plots)
 
<<fit pln, cache=TRUE>>=
pln <- fitpoilog(N.ind)
par(mfrow=c(2,2))
plot(pln)
par(mfrow=c(1,1))
@ %def 


\subsubsection*{Estimating species richness from PLN}

The fitted PLN allows to estimate the probability value assigned to species that
had zero abundance in the sample:

<<PLN species richness estimate 2>>=
pln.cf <- coef(pln)
(pln.d0 <- dpoilog(0, mu = pln.cf[1], sig=pln.cf[2]))
@ 

That is, an estimate that the recorded species are \Sexpr{round(100-pln.d0*100,0)}\%
of the total number of species.
This gives an estimate of \Sexpr{round(Sobs/(1-pln.d0))} species.


\subsection*{Log-series}

Log-series seems to overestimate the number of singletons
and to underestimate the abundance of species with intermediary abundances
(between 16 and 64 individuals, see octave plot). Also, the qq-plot shows that
the model underestimates the larger abundances.

 
<<fit ls>>=
y.ls <- fitls(N.ind)
par(mfrow=c(2,2))
plot(y.ls)
par(mfrow=c(1,1))
@ %def 

\subsubsection*{Estimate of species richness from LS}

From the value of $\alpha$ estimated from the sample of plots:
 
<<estimated S ls>>=
alpha <- coef(y.ls)[[2]]
(S.ls <- alpha*log(1 + Tot.t/alpha))
@ %def 

And here is the confidence interval for Fisher's $\alpha$ and the
interval for estimated total richness from these values

<<ls and S est for ls>>=
(ls.ci <- confint(y.ls))
## Estimated species richness for lower bound of alpha's IC
ls.ci[1]*log(1 + Tot.t/ls.ci[1])
ls.ci[2]*log(1 + Tot.t/ls.ci[2])
@ 

\subsection*{Zero-truncated Negative binomial}
\label{sec:negbin}

Here I use the method proposed by \citet{tovo2017}. The first step is
to fit a zero-truncated negative binomial (TNB) to the abundances in the sample.
I did that with the \emph{VGAM} package (as the authors did)
and also with the \emph{sads} package. 
The results were similar, and the fit looks identical to
those provided by the log-series (but has much lower AIC value, see below).
 
<<fit NB, cache=TRUE>>=
## With VGAM
y.nb <- vglm(N.ind ~ 1, posnegbinomial)
## With sads
y.nb2 <- fitnbinom(N.ind, 
                   start.value=c(size=0.3, mu=mean(N.ind)))
## Comparing: 
exp(coef(y.nb))
coef(y.nb2)
@ %def 

<<nb plots>>=
par(mfrow=c(2,2))
plot(y.nb2)
par(mfrow=c(1,1))
@ 


\subsubsection*{Estimate of  species richness}

Following the recipe of \citet{tovo2017}:

 
<<Tovo S estimate>>=
cf.nb <- coef(y.nb2)
csi.p <- unname(cf.nb[2]/(sum(cf.nb)))
csi <- csi.p/(p1+(1-p1)*csi.p)
## Estimated number of species 
S.nb <- Sobs*(1-(1-csi)^cf.nb[1]) / (1-(1-csi.p)^cf.nb[1])
(S.nb <- unname(S.nb))
@ %def 

I did a simple function to automate the calculations and to return
the confidence intervals, based on the confidence intervals of the 
coefficients of the NB fit (see file \code{functions.R})

 
<<NB S est CI>>=
(tovo.S <- tovo(fit = y.nb2, p = p1, CI=TRUE))
@ %def 


\subsection*{Model selection}

Among the three models, TNB
provides the best fit to the abundances in the sample:

 
<<model selection>>=
AICtab(pln, y.nb2, y.ls, base=TRUE)
@ %def 

TNB overestimates the higher abundances, while the logseries
underestimates the lower abundances in the sample:

<<Comparing LS and NB, echo=FALSE>>=
par(mfrow=c(2,2))
ls.rad <- radpred(y.ls)
nb.rad <- radpred(y.nb2)
plot(ls.rad$abund, nb.rad$abund, log="xy",
     xlab="Logseries theor. quantiles",
     ylab="TNB theor. quantiles", 
     col="grey", cex=0.25)
abline(0,1, col="blue")
plot(rad(Dec2018$N.ind), col="grey", cex=0.5)
lines(ls.rad)
lines(nb.rad, col="red")
legend("topright", c("LS", "NB"), col=c("blue","red"), 
       lty=1, bty="n")
ls.oc <- octavpred(y.ls)
nb.oc <- octavpred(y.nb2)
plot(octav(Dec2018$N.ind), ylim=range(c(ls.oc$Freq, nb.oc$Freq)))
lines(ls.oc)
lines(nb.oc, col="red")
legend("topright", c("LS", "NB"), col=c("blue","red"), 
       lty=1, bty="n")
par(mfrow=c(1,1))
@ 

\section{Estimates based in the RAD of population sizes}

\subsection*{Linear extrapolation from the regional RAD}

Here I replicated the extrapolation method from the RAD of the
estimated abundances for the whole Amazonia first for the logseries projection:

<<Linear extrapolation from regional RAD>>=
S.ulrich <- ulrich(Dec2018$population)
(S.r.ls <- S.ulrich$S[1])
@ 

Which are exactly the value reported in the manuscript (\Sexpr{round(S.r.ls)} species). 
Thus, from this estimate the value of Fisher's $\alpha$ for the whole Amazon is

<<Amazon alpha>>=
(alpha.r <- fishers.alpha(N = Tot.t, S = S.r.ls))
@ 

And with this estimate of regional $\alpha$ we can build a RAD for the Amazon \citep{tersteege2013}.
I made a function to calculate the regional RAD which runs faster than the original code.
Using it we get the log-series RAD for the whole region (Amazon):

<<amazon LS rad>>=
reg.ls.rad <- ceiling(
    rad.ls(S = S.r.ls, N = Tot.t, alpha = alpha.r)$y
)
@ 

\subsubsection*{Lower limit of the linear extrapolation}

According to \citet{ulrich2005}, the estimate from the linear extrapolation of LS is an upper limit to the estimation of species. 
They propose that the same linear extrapolation assuming a log-normal is a lower-bound estimate.
Following their recipe (eq.2) such lower bound would be:

<<regional rad lognormal>>=
(S.ulrich$S[2])
@ 


\subsection*{Regional RAD from TNB}

The RAD of negative binomial was upscaled according to \citep{tovo2017} 
and gets to the number of species estimated by this method (section~\ref{sec:negbin}).
I did a function that returns this upscaled RAD pretty fast

<<TNB regionl RAD>>=
reg.nb.rad <- rad.posnegbin(S = S.nb, size = cf.nb[1], 
                            prob = 1-csi)$y
@ 

Now we have the LS and TNB regional RADs 
I will plot them with the RAD of estimated population sizes, and also
with the upper-bound and lower-bound estimate of species
obtained above.


<<nbinom rad, echo=FALSE>>=
cf.u <- S.ulrich$coefs
plot(rad(reg.ls.rad), col="red", lwd=2, type="n",
     ylim=c(1, max(Dec2018$population)))
points(rad(Dec2018$population), col="grey")
curve(exp(cf.u[1]+cf.u[2]*x), add=TRUE)
curve(exp(cf.u[1]-cf.u[3]+cf.u[2]*x), add=TRUE)
lines(rad(reg.nb.rad), col="blue", lwd=2)
lines(rad(reg.ls.rad), col="red", lwd=2)
legend("topright", c("LS", "TNB", "Linear upper/lower bounds"), 
       col=c("red", "blue", "black"), lty=1, lwd=2, bty="n")
@ 

The blue line is the RAD predicted by zero-truncated negative binomial upscaled to the total number of
trees in Amazonia. %Broken lines are approximated 95\% CIs. 
The red line is the upscaled log-series for the Amazon,
as sent by Hans ( file \code{script\_for\_Paulo.R} ). 
Black lines are the linear extrapolations for the 50\% 
central quantile of the estimated population sizes, for
the Log-series and log-normal model \citep{ulrich2005}.

The negative binomial has a power-bending factor that
results in a lower estimate of total richness, below to
the lower-limit of the linear extrapolations.

The next section has uses a Bayesian approach to identify
the regional RAD model and also the sampling model that 
best approximates the RAD of population sizes.

\section{Comparing population sizes predicted by LS and NB regional RADs}

\subsection*{Methods}

To check which RAD model would approximate better the total population sizes estimated
for the sampled species, we simulated samples from the Amazon RAD generated by the Log-series 
and Truncated Negative Binomial, with and without clumping. 
In both cases we assumed a random drawn of \Sexpr{N.plots} 1-ha plots
from the Amazon RADs, where the number of individuals of each species
in each plot followed a Poisson (random sampling) or a Negative Binomial (clumped sampling)
distribution. 

The simulated population sizes where the total population sizes taken from
the regional RAD, only for those species that had been recorded 
in the simulated sample. 
The probability of each species be not included in a sample of $N$ plots is  $P(0)=(1-p)^N$.

Where $p$ is the probability of occurrence in each plot. 
Given the density of the species per plot $\mu$, 
for a Poisson sample 

\begin{equation}
  \label{eq:3}
  P(0) = e^{-\mu} 
\end{equation} 

and for a Negative Binomial sample

\begin{equation}
  \label{eq:2}
  P(0) = \left( \frac{k}{k+\mu} \right)^k 
\end{equation}

Where $k$ is the dispersion parameter of the negative binomial distribution.
%This coefficient adds extra variance compared to a Poisson sampling.
Thus we simulated occurrences of each species by sampling presence/absences
from a Bernoulli distribution with probability of occurrence $1-P(0)$.

\subsubsection*{Simulating clumping coefficients}

For simulations of clumped sampling, 
we allowed interspecific variation in clumping, 
by allowing a different value of the dispersion coefficient ($k$) for each species.
Hence, we had to define the value of $k$ for each species in the regional
RADs. We did that by (i) estimating the values of $k$ for the sampled species and
then (ii) by using the relationship between $k$ and $\mu$ to estimate the values of $k$
of each species.

To estimate the values of the aggregation coefficients
of the sampled species
we assumed that the number of plots that each species has been recorded follows
a binomial distribution with a probability of occurrence in each plot of $p=1-P(0)$,
with $P(0)$ from equation~\ref{eq:2}.
The parameter $k$ was then estimated by numerically maximizing the
log-likelihood function of the binomial distribution:

\begin{equation}
  \mathcal{L}(k | \mu, N, f_0) \ =  \ f_0 \ln (1-p) + (N - f_0) \ln p
\end{equation}

Where $N$ is the total number of plots, $f_0$ is 
the number of plots where the species was not recorded.
This log-likelihood function is conditioned to $\mu$, because this parameter was 
set to the observed density of each species in the sample.

Once we estimated a value of $k$ for each species recorded, 
we fit a linear regression of these values in function of the
observed species densities in the sample, in log scale.
The commands and model summary are:

<<k x dens regression, cache=TRUE>>=
## estimating k parameter of a NB for each species 
Dec2018$dens.ha <- Dec2018$N.ind/Samp.A
Dec2018$k <- est.kv(mu=Dec2018$dens.ha, 
                  nzeroes=N.plots-Dec2018$N.plots, 
                  Nplots=N.plots)
lm.k <-lm(log(k)~log(dens.ha), 
          data=Dec2018, subset=k<1)
## Estimated regression standard error
lm.k.sigma <- summary(lm.k)$sigma
## Model summary
summary(lm.k)
@ 

And a plot of with the regression line is

<<lok k x log density plot, echo=FALSE>>=
plot(log(k)~log(dens.ha), data=Dec2018, 
     subset=k<1, xlab="Density (ind/ha)",
     ylab="Aggregation parameter of NB",
     col="grey")
abline(lm.k, col="blue", lwd=2)
@ 

We then used this regression model to set a value of $k$ for each species from
their abundances as predicted by the regional RAD. 
In each simulation we drawn a value of $\ln k$ for each species
in the Amazon RAD from a Normal distribution with the mean as
the predicted value from the linear regression above for the population
density of the species in the RAD. The standard deviation of these
Normal distributions was the standard error of the linear regression.

\subsubsection*{Fit to observed population sizes}
\label{sec:fit-observ-popul}

To check which model best describes the RAD of estimated population we
used an approximate Bayesian computation (ABC, \citet{csillery2010,csillery2012}). 
To do that I ran 
the simulations described above for each combination of RAD and sampling
for 6135 values of regional richness, drawn from a uniform
distribution between 10,000 and 20,000. In ABC this is the \emph{a priori}
distribution, which I set between the know number of species in Amazon and
twice it, which is higher the larger species estimate for Amazon I get.

The ABC method compares summary statistics from the simulations with those observed
in a dataset to assign (approximate) posterior probabilities to each competing model.
I used four statistics from the simulated population RADs: number of species, inverse of Simpson's index
(that is, Simpson's species equivalents), and mean an standard deviation of the log of abundances.

The observed values of the statistics are targets against the results of each simulations is compared with an standardized
Euclidean distance. The proportion of simulations of each model that are below a gives distance threshold estimates the
posterior probability of the model, and thus provides a model-selection criteria based on computational simulations.
A similar procedure is used to estimate the posterior distribution of the parameters of the simulation, which in this case
was only the total number of species in the regional RAD from which the simulated samples were drawn.

I used a rejection threshold of 0.025, which means that only the 2,5\% simulations that resulted in the smallest Euclidean
distances to the observed values of the summary statistics were kept to build posterior distributions.
The codes used to run ABC are in separated file (\code{abc.R}), as the simulations take some time to run.


\subsection*{Results}

ABC model selection, using a 5\% rejection threshold:

<<abc model selection>>=
## load simulation objects to be used by ABC
load("abc_1000_to_2000_S.RData")
## Target: observed number of species, Simpson's 1/D, 
## lmean, sdmean             
target <- c(Sobs, 
            D(Dec2018$population), 
            mean(log(Dec2018$population)), 
            sd(log(Dec2018$population)))
## Model selection
model.sel <- postpr(target = target,
                    index=sim.ids,
                    sumstat = all.sims,
                    tol=0.05, method="rejection",
                    corr=TRUE)
msel.s <- summary(model.sel)
@ 

The simulation of clumped sampling of a regional Log-Series 
provides the best approximation to the observed population sizes
(p= \Sexpr{msel.s$Prob[["LSclump"]]}).

The next step is to use the selected model to get the
posterior distribution of the total species richness
in Amazon:

<<posterior species richness>>=
## Posterior distribution of Species richness from the selected model
S.post1 <- abc(target = target, 
               param=data.frame(S=sim.y[sim.ids=="LSclump"]),
               sumstat = all.sims[sim.ids=="LSclump",],
               tol=0.025, method="rejection")
S.post1.s <- summary(S.post1)
hist(S.post1)
@ 

Which gives a mean estimate of \Sexpr{round(S.post1.s[4,])} species, which is close to
the estimate got by the linear extrapolation from the logseries.
The 95\% credibility interval is pretty wide 
(\Sexpr{round(S.post1.s[2,])}--\Sexpr{round(S.post1.s[6,])}),
but does not include the estimate from the TNB, nor the lower limit
of the linear extrapolation method (from the lognormal).

The figure below shows the RAD from the population sizes,
and from simulated clumped samples from  the LS RAD with the estimated species richness estimated by the linear methods, 
and the 95\% credibility LS RADs. The clumped samples were simulated 100 times and then the mean population sizes
were used to build the simulated RADs. The number of species of the LS used in each simulations
were the mean and the credibility intervals as above.

<<clumped LS RAD and CI, cache=TRUE>>=
## Predicted log(k) values for LS rad
reg.ls.rad.lk <- predict(lm.k, 
                         newdata=data.frame(dens.ha=reg.ls.rad/Tot.A))

## LS RAD with the lower CI
abc.ls.c.rad.l <- rad.ls(S = S.post1.s[2,],
                           N = Tot.t, 
                           alpha = fishers.alpha(Tot.t, S.post1.s[2,]))$y
## LS RAD with the upper CI
abc.ls.c.rad.u <- rad.ls(S = S.post1.s[6,],
                           N = Tot.t, 
                           alpha = fishers.alpha(Tot.t, S.post1.s[6,]))$y
## Simulated cluped samples
## from LS with species richness estimated from linear extrapolation
ls.clump <- NB.samp(rad = reg.ls.rad, tot.area = Tot.A, 
                    n.plots = N.plots, 
                    lmean.k = reg.ls.rad.lk, 
                    lsd.k = lm.k.sigma, 
                    nrep=100)
## From LS with richeness from posterior cerdible intervals
ls.s2 <- NB.samp(rad = abc.ls.c.rad.l, 
                 tot.area = Tot.A, 
                 n.plots = N.plots, 
                 lmean.k =  
                     predict(lm.k, 
                             newdata=data.frame(dens.ha=abc.ls.c.rad.l/Tot.A)),
                 lsd.k = lm.k.sigma, 
                 nrep=100)
ls.s3 <- NB.samp(rad = abc.ls.c.rad.u, 
                 tot.area = Tot.A, 
                 n.plots = N.plots, 
                 lmean.k =  
                     predict(lm.k, 
                             newdata=data.frame(dens.ha=abc.ls.c.rad.u/Tot.A)),
                 lsd.k = lm.k.sigma, 
                 nrep=100)
## Plot
plot(rad(Dec2018$population), col="grey",
     ylab = "Population size", xlim=c(1,sum(ls.s3>=1)))

lines(rad(ls.clump), lwd=2, col="blue")
lines(rad(ls.s2), lwd=2, col="blue", lty=2)
lines(rad(ls.s3), lwd=2, col="blue", lty=2)
@ 


I think the plot above is enough, but for the records below
is the old plot with the RADS simulated with clumped and random sampling
using the richness estimates from the linear extrapolation of LS
and from TNB.

<<sim popsizes LS and NB, cache=TRUE>>=
## Predicted log(k) values for LS rad
reg.ls.rad.lk <- predict(lm.k, 
                         newdata=data.frame(dens.ha=reg.ls.rad/Tot.A))
## Predicted log(k) values for TNB rad
reg.nb.rad.lk <- predict(lm.k, 
                           newdata=data.frame(dens.ha=reg.nb.rad/Tot.A))
## Simulation of population sizes from samples of each RAD
ls.rnd <- Pois.samp(rad = reg.ls.rad, tot.area = Tot.A, 
                    n.plots = N.plots, nrep=100)
nb.rnd <- Pois.samp(rad = reg.nb.rad, tot.area = Tot.A, 
                    n.plots = N.plots, nrep = 100)
nb.clump <- NB.samp(rad = reg.nb.rad, tot.area = Tot.A, 
                    n.plots = N.plots, 
                    lmean.k = reg.nb.rad.lk, 
                    lsd.k = lm.k.sigma, 
                    nrep = 100)
@ 


<<plot sampled RADS, echo=FALSE>>=
plot(rad(Dec2018$population), col="grey", log="y", xlim=c(1,5500),
     ylab = "Population size")
lines(rad(ls.rnd), lwd=2)
lines(rad(ls.clump), lwd=2, col="red")
lines(rad(nb.rnd), lwd=2, col="green")
lines(rad(nb.clump), lwd=2, col="black")
legend("topright", 
       c("LS, random sample", "LS, clumped sample", "NB, random sample", "NB, clumped sample"), 
       col=c("blue","red","green", "black"), lty=1, lwd=2, bty="n")
@ 

The aggregation coefficients estimated from the sample clearly show that
the species are clumped across 1-ha plots, and so that
Poisson sampling is not realistic. This would suffice to
discard the TNB RAD, as they only provides a realistic fit under Poisson sampling.
The ABC model selection confirmed clumped sample of the LS RAD as the
best approximation to the observed RAD of population sizes 
(though this model still overestimates evenness and variance of the RAD, see
diagnostics in the code).


\section{Parametric estimates from occupancies}

These methods use the data of the proportion of plots occupied by each species, which is directly linked to species-area curves.
The comprehensive revision by \citet{kunin2018} have improved versions of 
many of the methods I already tried 
(e.g. beta-binomial) and an indication of the best ones (see page 9, 2nd paragraph). 
One of them is  the pair linear extrapolation from Logseries/lognormal from \citet{ulrich2005}, which was used 
in the hyperdominance paper, which is nice. 
Below the estimates from the other two, which also are
of the same magnitude of the estimate got from the linear extrapolation of LS.


\subsection*{Shen \& He method}
\label{sec:shen--he}

This method is based on the occurrence-rank curves (ORC), which is the plot
of the number of plots each species was recorded in function of its rank.
\citet{shen2008} propose two variants of their method, one using
conditional likelihood functions and other using unconditional functions.

I used the unconditional likelihood method,
but using as starting values for parameters
$\alpha$ and $\beta$ the estimates from the conditional
likelihood (Equation 6).

<<shen estimate, eval=FALSE>>=
## table of frequencies of occurrences
Y <- data.frame(table(Dec2018$N.plots))
Y[,1] <- as.integer(as.character(Y[,1]))
## Estimate of alfa and beta (Eq.6)
## To be use as starting values for the uncoditional estimation below
ab.est <- shen.ab(Y = Y, t = N.plots, T = Tot.A, 
                start=list(lalpha=-11, lbeta=0), method="SANN")
#ab.est.p <- profile(ab.est)
cf.st1 <- coef(ab.est)
## Estimate with uncoditional likelihood (Eq.3)
ShenHe <- shen.S( Y = Y, t = N.plots, T = Tot.A, 
                start=c(list(lS=log(nrow(Dec2018))), as.list(cf.st1)), 
                method="SANN")
cf.st2 <- coef(ShenHe)
S.sh <- unname(exp(cf.st2[1]))
@

Estimates \Sexpr{round(S.sh)} species.


\subsection*{Hui's ORC model}
\label{sec:huis-orc-model}

Hui's ORC models as detailed in supplementary material \#1 in \citet{kunin2018}.
It is based in to the 
occurrence-rank curve (ORC), to which is fitted a bounded power law. 
This model is then upscaled and the resulting ORC is used to estimate
the total species richness.

<<Hui ORC estimate>>=
S.orc <- hui.orc(Dec2018$N.plots, effort=eff18)
orc.cf <- coef(S.orc$model)
@ 

For the Amazon, the estimated bounding factor of the power law
is very small, and the ORC model is linear in the extrapolation range.
Thus this method gives the highest species richness estimate we got so far: 
\Sexpr{round(S.orc$S.est)}.
Still, this estimate is within the posterior credibility interval
got from ABC.

<<ORC plots with Hui function>>=
x <- 1:nrow(Dec2018)
y <- exp(orc.cf[1])*exp(orc.cf[2]*x)*(x^orc.cf[3])
#plot(rad(Dec2018$N.plots), ylim=range(c(Dec2018$N.plots, y)))
#lines(rad(y))
x2 <- 1:S.orc$S.est
y2 <- exp(orc.cf[1]-log(eff18))*exp(orc.cf[2]*x2)*(x2^orc.cf[3])
plot(rad(y2), type="n")
points(rad(Dec2018$N.plots/eff18), col="grey")
lines(rad(y2), type="l")
@ 

\section{Concluding remarks}

\begin{itemize}
\item TNB was the selected model for the sample, probably because it better approximates the
  effect of clumping on the sampled SADs. 
\item Nevertheless, ABC shows that the best model for the RAD of population sizes is a clumped sampling of a regional LS RAD. 
\item ABC also provides a credibility interval of regional species richness that is wide but still informative.
\item Nevertheless, ABC posterior estimates of S and also diagnostics (see \code{abc.R} code) 
  shows that LS clumped sample overestimates some features of the SAD (to be discussed).
\item The recommended estimates by the most recent review on estimates based in upscaling \citep{kunin2018} 
  includes the linear extrapolation
  that was already used, and two other methods that estimated values within the ABC credibility interval.
\end{itemize}

\section{R codes}

\label{sec:r-codes}
 The file \code{functions.R} has functions to :
 \begin{enumerate}
 \item run each method of species richness estimates;
 \item calculate LS RAD faster than function \code{Make.RAD};
 \item calculate TNB RAD, faster than my previous code;
 \item simulate random and clumped samples of any RAD   
 \end{enumerate}
 
Documentation under construction in the Roxygen standard with the code of each function.
But I think what is documented and the scripts of this report (\code{estimates\_summary.R}) provide the basic cues
to run the estimates with other similar datasets (Renato's Mata Atlantica data, for example).


\bibliography{/home/paulo/work/resources/bib/geral.bib}

\end{document}
